---
title: "Network Features"
author: "Nicolas Restrepo"
date: "3/29/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(igraph)
library(brainGraph)
library(patchwork)
library(bayestestR)
library(netrankr)
library(ggrepel)
library(corrplot)
```

## Introduction 

Here, I am going to explore if some characteristics of the networks we have are related to how they respond to node removal. 

## Getting the Network features

Let's build the network. 

```{r}
# Import the data 
elephant_data <- read_csv("Data/dist.matrix.t1.csv")
# Transform data into square matrix
elephant_matrix <- elephant_data %>% 
  select(2:ncol(elephant_data)) %>% 
  as.matrix() 
# Change the names so that nodes have the same ID as in the dataset
node_IDs <- names(elephant_data)[2:ncol(elephant_data)]
colnames(elephant_matrix) <- node_IDs
rownames(elephant_matrix) <- node_IDs
# Build inverse matrix
inv_elephant_matrix <- matrix(1, 97, 97) - elephant_matrix
# Populate the diagonal with 0s
diag(inv_elephant_matrix) <- 0
# Now create the network
elephant_graph_inv <- 
graph_from_adjacency_matrix(inv_elephant_matrix, mode = "undirected", weighted = T)
```

I'll load the functions we need. 

```{r}
inverse_efficiency <- function(g) {
  # Turn it into an adjacency matrix 
  net_mat <- as_adj(g,
                    attr = 'weight', 
                    sparse = F)
  # Get the inverse matrix 
  mat_inv <- net_mat 
  edges <- which(mat_inv > 0)
  mat_inv[edges] <- 1.0001 - mat_inv[edges]
  # Populate the diagonal with 0s
  diag(mat_inv) <- 0
  
  # Create the new graph 
  net_inv <- graph_from_adjacency_matrix(mat_inv, 
                                         weighted = T, 
                                         mode = 'undirected')
  D <- distances(net_inv, 
                 weights = E(net_inv)$weight)
  D <- D + 1 
  diag(D) <- 0
  Nv <- nrow(D)
  Dinv <- 1/D
  eff <- colSums(Dinv * is.finite(Dinv), na.rm = T)/(Nv - 1)
  geff <- sum(eff)/length(eff)
  
  return(geff)
}
```

```{r}
decrease_efficiency <- function(g) {
  # Get the original efficiency
  og_geff <- inverse_efficiency(g)
  # A matrix to store the data
  removal_df <- matrix(NA, ncol = 6, nrow = length(V(g)))
  # Inverse network 
  net_mat <- as_adj(g, 
                    attr = "weight",
                    sparse = FALSE)
  # Get the inverse matrix 
  mat_inv <- net_mat 
  edges <- which(mat_inv > 0)
  mat_inv[edges] <- 1.0001 - mat_inv[edges]
  inv_network <- graph_from_adjacency_matrix(mat_inv,
                                             mode = "undirected",
                                             weighted = TRUE)
  for (i in 1:length(V(g))) {
    vert <- V(g)[i]
    deg <- degree(g)[vert]
    ecent <- eigen_centrality(g, weights = E(g)$weight)$vector[vert]
    bcent <- betweenness(g, directed = FALSE, weights = E(inv_network)$weight)[vert]
    net_mat <- as_adj(g, attr = 'weight', sparse = F)
    sum_weigths <- sum(net_mat[vert,], na.rm = T)
    ng <- delete.vertices(g, vert)
    eff <- inverse_efficiency(ng)
    removal_df[i,] <- c(names(vert), 
                        eff-og_geff,
                        deg,
                        sum_weigths, 
                        ecent, 
                        bcent)
  }
  
  removal_df <- data.frame(removal_df)
  names(removal_df) <- c("node_name", "change_efficiency",
                         "degree", "sum_edge_weights", 
                         "eigen_centrality", 
                         "betweenness")
  removal_df <- removal_df %>% 
  mutate_at(.vars = c("change_efficiency",
                      "degree", "sum_edge_weights", 
                      "eigen_centrality", 
                      "betweenness"), 
            as.numeric)
  
  return(removal_df)
}
```

```{r}
# Contagion model from Acerbi et al (2020)
info_contagion <- function(net, rewire, e = 1, r_max, sim = 1){
  
  # Rewire network if random is set to TRUE
  if(rewire){
    net <- rewire(graph = net, with = keeping_degseq(loops = F, niter = 10^3))
  }
  
  # Get adjacency matrix from network
  adjm <- get.adjacency(net, 
                        sparse = F, 
                        attr = "weight")
  
  # Turn adjacency matrix into boolean (TRUE / FALSE) - if you dont want weights
  # adjm_bool <- adjm > 0
  
  # Set number of individuals based adjacency matrix
  N <- vcount(net)
  
  # Create a vector indicating possession of info and set one entry to TRUE
  info <- rep(FALSE, N)
  info[sample(x = N, size = 1)] <- TRUE
  
  # Create a reporting variable
  proportion <- rep(0, r_max)
  
  # Rounds
  for(r in 1:r_max){
    # In random sequence go through all individuals without info
    for(i in sample(N)){
      # Select i's neighbourhood 
      nei <- adjm[i,] > 0
      # If you dont want to include weights, quote above, unquote below
      #nei <- adjm_bool[i,]
      # Proceed if there is at least one neighbour
      if(sum(nei) > 0){
        # Simple contagion for e = 1 and complex contagion for e = 2
        if(runif(n = 1, min = 0, max = 1) <= (sum(adjm[i,][info])/length(nei))^e){
          info[i] <- TRUE
        }
      }
    }
    # Record proportion of the population with info
    proportion[r] <- sum(info) / N
    # Increment the round counter
    r <- r + 1
  }
  # Return a tibble with simulation results
  return(tibble(time = 1:r_max, 
                proportion = proportion, 
                time_to_max = which(proportion == max(proportion))[1],
                e = e, 
                network = ifelse(test = rewire, yes = "random", no = "model output"),
                sim = sim))
}
turn_reached_max_decrease <- function(ev, g, g2, reps, turns) {
  # Place holder 
  values <- rep(NA, reps)
  
  for (i in 1:reps) {
    sim <- info_contagion(g, 
                          rewire = F, 
                          e = ev, 
                          r_max = turns)
    ttm <- sim$time_to_max[1]
  
    # Now some centrality removal
    sim_r <- info_contagion(g2, 
                            rewire = F, 
                            e = ev, 
                            r_max = turns)
    ttmr <- sim_r$time_to_max[1]
    
    values[i] <- ttm-ttmr
  }
  return(values)
}
# Function to calculate the AUC of multiple runs
multiple_diff_auc <- function(ev, g, g2, reps, turns) {
  # Place holder 
  values <- rep(NA, reps)
  
  for (i in 1:reps) {
    sim <- info_contagion(g, 
                           rewire = F, 
                           e = ev, 
                           r_max = turns)
    auc_nr <- area_under_curve(x = sim$time, 
                            y = sim$proportion)
    
  # Now with removal
  sim_r <- info_contagion(g2, 
                           rewire = F, 
                           e = ev, 
                           r_max = turns)
  auc_r <- area_under_curve(x = sim_r$time, 
                            y = sim_r$proportion)
  
  diff <- auc_r/auc_nr
  
    values[i] <- diff
  }
  return(values)
}
```

Now, we have to decide what network features we are interested in. I will start with the following: 

- Density 
- Number of edges
- Number of nodes 
- Modularity 
- Average transitivity

Let's see how we can retrieve all that information. 

```{r}

multiple_network_features <- function(net) {
# Edge density 
dens <- edge_density(net)
# Now community detection and modularity
louvain_communities <- cluster_louvain(net)
mod <- modularity(net, membership(louvain_communities))
# Average transitivity 
avg_trans <- transitivity(net, type = 'average')
# Find out about removals 
removals <- decrease_efficiency(net)
# Get the correlations 
# Correlation for degree 
cor_degree <- cor(removals$change_efficiency, removals$degree)
# Correlation sum of edge weights 
cor_sew <- cor(removals$change_efficiency, removals$sum_edge_weights)
# Correlation eigen 
cor_eigen <- cor(removals$change_efficiency, removals$eigen_centrality)
# Correlation betweeness 
cor_betweenness <- cor(removals$change_efficiency, removals$betweenness)
# Remove the top 10 in efficiency 
top_nodes_targeted <- removals %>% 
  arrange(change_efficiency) %>% 
  slice(1:10) %>% 
  pull(node_name)
# Pull top 10 centrality
top_nodes_cent<- removals %>% 
  arrange(desc(betweenness)) %>% 
  slice(1:10) %>% 
  pull(node_name)
# Remove the vertex with highest impact 
net_rems_targeted <- delete.vertices(net, V(net)[top_nodes_targeted])
net_rems_cent <- delete.vertices(net, V(net)[top_nodes_cent])
# Run simulations
auc_diffs_targeted <- multiple_diff_auc(ev = 1, 
                                        g = net, 
                                        g2 = net_rems_targeted,
                                        reps = 100, 
                                        turns = 500)
auc_diffs_centrality <- multiple_diff_auc(ev = 1, 
                                          g = net, 
                                          g2 = net_rems_cent,
                                          reps = 100, 
                                          turns = 500)

median_aucs_targ <- median(auc_diffs_targeted)
median_aucs_cent <- median(auc_diffs_centrality)
sd_aucs_targ <- sd(auc_diffs_targeted)
sd_aucs_cent <- sd(auc_diffs_centrality)

# Difference in efficiencies 
change_eff_targeted <- inverse_efficiency(net_rems_targeted)-inverse_efficiency(net)
change_eff_cent <- inverse_efficiency(net_rems_cent)-inverse_efficiency(net)
# All results the function will produce
net_features <- c(num_nodes = length(V(net)), 
                  num_edges = length(E(net)), 
                  change_eff_targeted = change_eff_targeted,
                  change_eff_cent = change_eff_cent,
                  median_aucs_targ = median_aucs_targ,
                  median_aucs_cent = median_aucs_cent,
                  sd_aucs_targ = sd_aucs_targ,
                  sd_aucs_cent = sd_aucs_cent,
                  cor_betweenness = cor_betweenness, 
                  cor_eigen = cor_eigen, 
                  cor_sew = cor_sew, 
                  cor_degree = cor_degree, 
                  avg_trans = avg_trans, 
                  mod = mod, 
                  dens = dens)

return(net_features)
}

```

Now, I am going to build all the networks we have and then iterate over this function. 

```{r}
# Network for wave 2 elephant data 
# Import the data 
elephant_data_w2 <- read_csv("Data/dist.matrix.t2.csv")
# Transform data into square matrix
elephant_matrix_w2 <- elephant_data_w2 %>% 
  select(2:ncol(elephant_data_w2)) %>% 
  as.matrix() 
# Change the names so that nodes have the same ID as in the dataset
node_IDs <- names(elephant_data_w2)[2:ncol(elephant_data_w2)]
colnames(elephant_matrix_w2) <- node_IDs
rownames(elephant_matrix_w2) <- node_IDs
# Build inverse matrix
inv_elephant_matrix_w2 <- matrix(1, 130, 130) - elephant_matrix_w2
# Populate the diagonal with 0s
diag(inv_elephant_matrix_w2) <- 0
# Replace with NAs with 0s 
inv_elephant_matrix_w2 <- replace_na(inv_elephant_matrix_w2, 0)
# Now create the network
elephant_graph_w2<- 
graph_from_adjacency_matrix(inv_elephant_matrix_w2, mode = "undirected", weighted = T)

# Network elephant data wave 3 
# Import the data 
elephant_data_w3 <- read_csv("Data/dist.matrix.t3.csv")
# Transform data into square matrix
elephant_matrix_w3 <- elephant_data_w3 %>% 
  select(2:ncol(elephant_data_w3)) %>% 
  as.matrix() 
# Change the names so that nodes have the same ID as in the dataset
node_IDs <- names(elephant_data_w3)[2:ncol(elephant_data_w3)]
colnames(elephant_matrix_w3) <- node_IDs
rownames(elephant_matrix_w3) <- node_IDs
# Build inverse matrix
inv_elephant_matrix_w3 <- matrix(1, 120, 120) - elephant_matrix_w3
# Populate the diagonal with 0s
diag(inv_elephant_matrix_w3) <- 0
# Replace with NAs with 0s 
inv_elephant_matrix_w3 <- replace_na(inv_elephant_matrix_w3, 0)
# Now create the network
elephant_graph_w3<- 
graph_from_adjacency_matrix(inv_elephant_matrix_w3, mode = "undirected", weighted = T)

# Network dolphin data wave 1
# Import the data
dolphin_edge_lists <- read_csv("Data/dolphin_edge_lists.csv")

# Write function to return the graph from a wave
# Function to plot the networks 
dolphin_edgelist <- function(w, t) {
  # Conditional statements for the waves 
  if (w == 1) {
    c <- "T2008"
    title <- "Wave 1"
  } else {
    if(w ==2) {
      c <- "T2010"
      title <- "Wave 2"
    } else {
      if (w==3) {
        c <- "T2012"
        title <- "Wave 3"
      } else {
        if (w == 4) {
          c <- "T2014"
          title <- "Wave 4"
        } else {
          if (w == 5) {
            c <- "T2016"
            title <- "Wave 5"
          } else {
            c <- "T2018"
            title <- "Wave 6"
          }
        }
      }
    }
  }
  # Take the wave 
  edgelist <- dolphin_edge_lists %>% 
    select(1,2, c, 9) %>% 
    filter(!is.na(.[,3]) & .[,3] > t) %>% 
    rename(weight = c, 
           from = ID1, 
           to = ID2)
  
  net <- graph_from_data_frame(edgelist, directed = FALSE)
  return(net)
}
# Import the ID list data 
# Contains removal information 
id_list <- read_csv("Data/ID_list.csv")
dolphin_w1 <- dolphin_edgelist(w = 1, 
                               t = 0)

# Dolphin wave 2
dolphin_w2 <- dolphin_edgelist(w = 2, 
                               t = 0)

# Dolphin wave 3
dolphin_w3 <- dolphin_edgelist(w = 3, 
                               t = 0)

# Dolphin wave 4 
dolphin_w4 <- dolphin_edgelist(w = 4, 
                               t = 0)

# Dolphin wave 5 
dolphin_w5 <- dolphin_edgelist(w = 5, 
                               t = 0)

# Dolphin wave 6 
dolphin_w6 <- dolphin_edgelist(w = 6, 
                               t = 0)
```

Now, I will backbone the networks to preserve only 25% of the edges. 

```{r}
backbone_graph <- function(alpha, simple, g) {
  
# All edges and their weight 
e <- cbind(igraph::as_data_frame(g)[, 1:2 ], 
           weight = E(g)$weight)

# Add graph strength and in degree of each source to graph dataframe
# in
# Sum all edge weigths for each node 
w_in <- graph.strength(g,
                       mode = "in")
w_in <- data.frame(to = names(w_in), 
                   w_in, stringsAsFactors = FALSE)
# Get the degree for each node 
k_in <- degree(g, mode = "in")
k_in <- data.frame(to = names(k_in), 
                   k_in, 
                   stringsAsFactors = FALSE)

# Join them both 
e_in <- e %>%
  left_join(w_in, by = "to") %>%
  left_join(k_in, by = "to") %>%
  mutate(alpha_in = (1-(weight/w_in))^(k_in-1))

# Same for out degree 
w_out <- graph.strength(g, mode = "out")
w_out <- data.frame(from = names(w_out), w_out, stringsAsFactors = FALSE)
k_out <- degree(g, mode = "out")
k_out <- data.frame(from = names(k_out), k_out, stringsAsFactors = FALSE)

e_out <- e %>%
  left_join(w_out, by = "from") %>%
  left_join(k_out, by = "from") %>%
  mutate(alpha_out = (1-(weight/w_out))^(k_out-1))

# Join everything and add alpha to the network
#full
e_full <- left_join(e_in, 
                    e_out, 
                    by = c("from", "to", "weight"))

e_full <- e_full %>%
  mutate(alpha = ifelse(alpha_in < alpha_out, alpha_in, alpha_out)) %>%
  select(from, to, alpha)

E(g)$alpha <- e_full$alpha

# Finally prune the network 
graph_pruned <- delete.edges(g, 
                             which(E(g)$alpha >= alpha))
graph_pruned_deleted <- delete.vertices(graph_pruned, 
                                        which(degree(graph_pruned) == 0))

# Count number of vertices
num_e <- gsize(graph_pruned)
num_v <- gorder(graph_pruned_deleted)

res <- c(num_e, num_v)

# return statement 
if (simple == T) {
  return(res)
} else {
  return(list(res, graph_pruned))
}
}

backbone_ew1_25 <- backbone_graph(alpha = 0.4, 
                               simple = F, 
                               g = elephant_graph_inv)
enet_w1 <- backbone_ew1_25[[2]]
backbone_ew2_25 <- backbone_graph(alpha = 0.4, 
                               simple = F, 
                               g = elephant_graph_w2)
enet_w2 <- backbone_ew2_25[[2]]
backbone_ew3_25 <- backbone_graph(alpha = 0.36, 
                               simple = F, 
                               g = elephant_graph_w3)
enet_w3 <- backbone_ew3_25[[2]]
backbone_dw1_25 <- backbone_graph(alpha = 0.25, 
                               simple = F, 
                               g = dolphin_w1)
dnet_w1 <- backbone_dw1_25[[2]]
backbone_dw2_25 <- backbone_graph(alpha = 0.23, 
                               simple = F, 
                               g = dolphin_w2)
dnet_w2 <- backbone_dw2_25[[2]]
backbone_dw3_25 <- backbone_graph(alpha = 0.24, 
                               simple = F, 
                               g = dolphin_w3)
dnet_w3 <- backbone_dw3_25[[2]]
backbone_dw4_25 <- backbone_graph(alpha = 0.26, 
                               simple = F, 
                               g = dolphin_w4)
dnet_w4 <- backbone_dw4_25[[2]]
backbone_dw5_25 <- backbone_graph(alpha = 0.25, 
                               simple = F, 
                               g = dolphin_w5)
dnet_w5 <- backbone_dw5_25[[2]]
backbone_dw6_25 <- backbone_graph(alpha = 0.25, 
                               simple = F, 
                               g = dolphin_w6)
dnet_w6 <- backbone_dw6_25[[2]]
```

Now, I'm going to try to run the function. 

```{r}
all_networks <- list(elephant_graph_inv, 
                     elephant_graph_w2, 
                     elephant_graph_w3, 
                     enet_w1, 
                     enet_w2, 
                     enet_w3,
                     dolphin_w1, 
                     dolphin_w2, 
                     dolphin_w3, 
                     dolphin_w4, 
                     dolphin_w5, 
                     dolphin_w6, 
                     dnet_w1, 
                     dnet_w2, 
                     dnet_w3, 
                     dnet_w4, 
                     dnet_w5, 
                     dnet_w6)
set.seed(76)
network_features_df <- map_df(all_networks, 
                              multiple_network_features)
```

Let's save the dataframe

```{r}
write_csv(network_features_df, 
          "Data/network_features.csv")
```

