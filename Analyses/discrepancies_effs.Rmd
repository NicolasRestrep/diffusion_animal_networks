---
title: "Differences in Local and Global Efficiency"
author: "Nicolas Restrepo"
date: "2/17/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction 

I am going to use this document for thinking about the discrepancies we have seen between what parameter combinations produce the highes global and local efficiency. 

## Distribution of Efficiencies

I am going to begin by plotting the distributions of global and local efficiencies for beta 2.5 and our radii of interest. 

```{r}
library(brainGraph)
library(tidyverse)
library(igraph)
library(patchwork)
```

```{r}
fifty_runs <- read_csv("fifty_runs.csv")

get_full_network <- function(run,turns,N) {
  # Data for just one run
  tm_data <- read.delim(run,
                        header = F, sep = ',')
  # Let's get board coordinates for the each time step 
  # Create function to extract a matrix of coordinates for each time-step
  get_coordinates <- function(x, num_agents) {
    tm <- tm_data[x,-ncol(tm_data)] %>% as_vector() %>% matrix(nrow = num_agents, ncol = 4, byrow = T)
    colnames(tm) <- c('monkey', 'x_coord', 'y_coord', 'fruit')
    return(tm)
  }
  # Iterate over all time-steps
  full_coord_list <- map(c(1:turns), get_coordinates, num_agents=N)
  # Now I am going to create a function to extract network matrices 
  get_network_matrix <- function(x) {
    # extract dataset for the coordinates of one time-step 
    coord <- full_coord_list[[x]] %>% as.data.frame(.)
    # Empty placeholder matrix
    net_mat <- matrix(0, N, N)  
    for (j in 1:N) {
      # Coordinates for where agent j is 
      mcx <- coord$x_coord[j] 
      mcy <- coord$y_coord[j]
      # Are there any monkeys there 
      coincide <- which(coord$x_coord==mcx & coord$y_coord==mcy)
      # If there are record on the network matrix
      for (i in 1:length(coincide)) {
        net_mat[j,coincide[[i]]] <- 1
      }
    }
    return(net_mat)
  }
  # Let's get all networks 
  full_matrix_list <- map(c(1:turns), get_network_matrix)
  # Now let's sum all the ties recorded across all time-steps
  full_matrix <- Reduce("+", full_matrix_list)
  # Get rid of the diagonal because it's meaningless 
  diag(full_matrix) <- 0
  # Create network
  network <- graph_from_adjacency_matrix(full_matrix, mode = "undirected", weighted = T)
  return(network)
}

p1 <- fifty_runs %>% 
  filter(beta == 2.5 & radius %in% c(0.1, 0.01)) %>% 
  mutate(radius = as.factor(radius)) %>% 
  ggplot(aes(x = local, fill = radius)) +
  geom_density(alpha = 0.3)  + 
  theme_minimal() + 
  theme(legend.position = 'bottom') +
  labs(title = "Local Efficiency", 
       x = "")


p2 <- fifty_runs %>% 
  filter(beta == 2.5 & radius %in% c(0.1, 0.01)) %>% 
  mutate(radius = as.factor(radius)) %>% 
  ggplot(aes(x = global, fill = radius)) +
  geom_density(alpha = 0.3)  + 
  theme_minimal() + 
  theme(legend.position = 'bottom') +
  labs(title = "Global Efficiency", 
       x = "")

(p1 | p2)
```

We notice there's a difference here. While the contrast is clear in global efficiency, the distributions look very similar when it comes to local efficiency. Why? I think - as Ketika and Cecilia suggested - it has to do with components and "reaching out" beyond your subgraph. 

Let's look at the distribution of components across both radii. 

```{r}
fifty_runs %>% 
  filter(beta == 2.5 & radius %in% c(0.1, 0.01)) %>% 
  mutate(radius = as.factor(radius)) %>% 
  ggplot(aes(x = comps, fill = radius)) +
  geom_density(alpha = 0.3) + 
  theme_minimal() +
  labs(title = "Components across radii", 
       x = "")
```

Radius 0.01 exhibits more components in general, which means there will more subgraphs. This means that - by definition - the global efficiency will be lower. 

Let's look at the most efficient network in both parameter specifications:

```{r}
global_net <- get_full_network(run = "/Users/nrestrepo/Downloads/cp_monkey100/beta2.5/monos100/radius0.1/13.txt", 
                               N = 100, 
                               turns = 100)
local_net <- get_full_network(run = "/Users/nrestrepo/Downloads/cp_monkey100/beta2.5/monos100/radius0.1/32.txt", 
                              N = 100, 
                              turns = 100)

plot(local_net, 
     layout = layout.fruchterman.reingold, 
     vertex.label = "", vertex.size = 2, vertex.color = "white", 
     edge.width = E(local_net)$weight/50, 
     main = "Radius 0.01") 

plot(global_net, 
     layout = layout.fruchterman.reingold, 
     vertex.label = "", vertex.size = 2, vertex.color = "white", 
     edge.width = E(local_net)$weight/50, 
     main = "Radius 0.1")

```

The one for radius 0.01 contains two main subgraphs which are disconected. The other network only has one main component. 

What I think it's happening here is that local efficiency is "leveling the playing field" because it does not consider the fact that the subgraphs are disconnected. Thus, if we get two densely interconnected yet exclusive from each other, the local efficiency would be high. Global efficiency takes the graph as a whole. This means that the graphs that are fully connected might have lower local efficiency, because the only subgraph - main component - gets judged as a whole. While networks that are fractured might get a bump in efficiency because the efficiency of their subgraphs is examined independently. 

Now, the question is **why** we get more components in radius = 0.01 than in radius 0.1. I think movement might well be the best explanation. 